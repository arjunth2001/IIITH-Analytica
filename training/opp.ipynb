{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d81a0b-107d-49eb-8f14-8f58a6f54e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import emoji\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b713d-7709-47ff-9ccd-0166a14c647e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328e51bf55624c59bdea3e4f64c4282c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2bb6ec58c344979ae200902f540986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147a19f6ab1f40e69a23a08eda1ccca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fee838275a047a580ba1a75aa43f449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a63d213c864226910859a98714c858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a160bfb6-da22-47c0-b7f1-0037b23ce2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "  cleanr = re.compile('<.*?>')\n",
    "  cleantext = re.sub(cleanr, '', raw_html)\n",
    "  return cleantext\n",
    "\n",
    "def removePattern(text, pattern):\n",
    "\n",
    "    r = re.findall(pattern, text)\n",
    "\n",
    "    for i in r:\n",
    "\n",
    "        text = re.sub(i, '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def remove_urls (vTEXT):\n",
    "    vTEXT = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', vTEXT, flags=re.MULTILINE)\n",
    "    return(vTEXT)\n",
    "\n",
    "def clean_text(text):\n",
    "    if type(text)!=str:\n",
    "        return text\n",
    "    text = text.lower()  # lower case\n",
    "    text = remove_urls(text)\n",
    "    text = cleanhtml(text)\n",
    "    text = removePattern(text, \"@[\\w]*\")  # remove handles\n",
    "    text = removePattern(text, \"&[\\w]*\")  # remove &amp\n",
    "    # remove special characters, punctuations\n",
    "    text = re.sub('[!@$:);/#,.*$?ред&\"]', '', text)\n",
    "    text = emoji.get_emoji_regexp().sub(u'', text)  # remove emoji\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71804376-1e51-4542-9690-baca3eba98fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(x):\n",
    "  labels=['First Party Collection/Use',\n",
    "          'Third Party Sharing/Collection',\n",
    "          'Other',\n",
    "          'International and Specific Audiences',\n",
    "          'Data Security',\n",
    "          'User Choice/Control',\n",
    "          'User Access, Edit and Deletion',\n",
    "          'Data Retention',\n",
    "          'Policy Change',\n",
    "          'Do Not Track']\n",
    "  return labels.index(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d020cdf-e79c-45ea-947b-ffd87f5d0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrivacyDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.df[\"text\"] = self.df[\"text\"].progress_apply(lambda x:clean_text(x))\n",
    "        self.df[\"label\"] = self.df[\"data_practice\"].progress_apply(lambda x:encode_label(x))\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        model_input = self.df['text'][idx]            \n",
    "        encoded_sent = self.tokenizer.encode_plus(\n",
    "            text=model_input, \n",
    "            add_special_tokens=True,       \n",
    "            max_length=512,                  \n",
    "            padding='max_length',          \n",
    "            return_attention_mask=True, \n",
    "            truncation=True\n",
    "            )\n",
    "        \n",
    "        input_ids = encoded_sent.get('input_ids')\n",
    "        attention_mask = encoded_sent.get('attention_mask')\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        attention_mask = torch.tensor(attention_mask)        \n",
    "\n",
    "        label = torch.tensor(self.df['label'][idx])\n",
    "        \n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d07642-c93d-4cc8-afe4-a5a6810428c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac8f34-c171-4418-a335-ed415202fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PrivacyDataset(pd.read_csv(\"../datasets/OPP/train.csv\"), tokenizer)\n",
    "test_dataset = PrivacyDataset(pd.read_csv(\"../datasets/OPP/val.csv\"), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bda7f4-0fde-4f38-a765-b432ec3d2ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric1 = load_metric(\"accuracy\")\n",
    "metric2 = load_metric(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965330b-1b2a-4b54-8cbe-5476f16183a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = metric1.compute(predictions=predictions, references=labels)\n",
    "    f1 = metric2.compute(predictions=predictions, references=labels)\n",
    "    return {'accuracy': accuracy[\"accuracy\"], 'f1-score': f1[\"f1\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2036b23-ceee-41b2-9d4f-6af3c4f468f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='/scratch/arjunth2001/opp_results',          # output directory\n",
    "    num_train_epochs=15,            # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
    "    warmup_steps=500,               # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,              # strength of weight decay\n",
    "    logging_dir='/scratch/arjunth2001/opp_logs',           # directory for storing logs\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_steps=250,\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit = 1,\n",
    "    learning_rate = 0.00001,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model =\"eval_f1-score\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc195cb-bc9a-42e6-ae83-f8b4bdcfcb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset,           # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15acf32a-f965-4ea2-b339-00d0d8a1c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f231d5-7246-48a1-aaef-de318d248cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./model_opp115\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccaa9d-c761-4378-a556-efb3f55358b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
